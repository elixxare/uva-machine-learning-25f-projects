# -*- coding: utf-8 -*-
"""artists_messages.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wpvrUtO-1ziY6Lt9vfVQNHPGdBW8ck7J
"""

#upload data from kaggle using API token
!pip install kaggle
!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

#download dataset (Genius Song Lyrics)
!kaggle datasets download -d carlosgdcj/genius-song-lyrics-with-language-information

#necessary imports/installations
import zipfile
import pandas as pd
import nltk
nltk.download('punkt')
nltk.download('punkt_tab')
!pip install sentence-transformers
from sentence_transformers import SentenceTransformer
from sklearn.cluster import KMeans
from sklearn.feature_extraction.text import TfidfVectorizer
import matplotlib.pyplot as plt
import seaborn as sns
from matplotlib.ticker import FuncFormatter

#unzip the dataset to access the CSV file
with zipfile.ZipFile('genius-song-lyrics-with-language-information.zip', 'r') as zip_ref:
    zip_ref.extractall('lyrics_data')

#filter dataset (including only artist and lyrics columns, for our 6 chosen artists)

#selected artists
artists = [
    "taylor swift", "drake", "kendrick lamar",
    "bad bunny", "billie eilish", "the weeknd"
]
artists_lower = [a.lower() for a in artists]
#process chunks of the dataset at a time to avoid consuming RAM (100,000 rows per chunk)
chunksize = 100_000
filtered_rows = []
#add filtered rows for all chunks
for chunk in pd.read_csv('/content/lyrics_data/song_lyrics.csv', chunksize=chunksize, usecols=['artist', 'lyrics']):
    chunk['artist_clean'] = chunk['artist'].str.lower().str.strip()
    filtered = chunk[chunk['artist_clean'].isin(artists_lower)]
    filtered_rows.append(filtered)
#combine all filtered chunks into one dataframe
df = pd.concat(filtered_rows, ignore_index=True)
display(df)

#display number of songs per artist in dataset
df['artist_clean'].value_counts()

#split lyrics into short text units using NLTK
df['sentences'] = df['lyrics'].apply(nltk.sent_tokenize)
exploded = df.explode('sentences')
#remove extremely short sentences
exploded = exploded[exploded['sentences'].str.len() > 10]
exploded.reset_index(drop=True, inplace=True)
exploded.head()

#embed sentences with Sentence-BERT
model = SentenceTransformer("all-mpnet-base-v2")
#compute embeddings
sentences = exploded['sentences'].tolist()
#batch encoding process for better memory usage
embeddings = model.encode(
    sentences,
    batch_size=64,
    show_progress_bar=True
)

#cluster sentences using k-means clustering
k = 12
kmeans = KMeans(n_clusters=k, random_state=42)
exploded['cluster'] = kmeans.fit_predict(embeddings)

#use TF-IDF to explore each cluster
vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)
tfidf = vectorizer.fit_transform(exploded['sentences'])
terms = vectorizer.get_feature_names_out()
#identify top ten most important key words per cluster
def top_keywords(cluster_id, n=10):
    idx = exploded['cluster'] == cluster_id
    cluster_tfidf = tfidf[idx.values].mean(axis=0)
    top_indices = cluster_tfidf.A1.argsort()[-n:][::-1]
    return [terms[i] for i in top_indices]
#display words per cluster
for c in range(k):
    print(f"Cluster {c}: {top_keywords(c)}")

#manually label clusters as themes
theme_map = {
    0: "Love", #'love', 'baby', 'girl'
    1: "Musical/Lyrical Structure", #words like verse and chorus
    2: "Introspection", #'know', 'clear', 'right'
    3: "General Spanish Phrases",
    4: "Aggression", #cuss words
    5: "Shout-outs and references", #'thank', 'message'
    6: "Emotions", #'feel', 'life'
    7: "Music Industry", #'music', 'album', 'songs'
    8: "Desire", #'want', 'love'
    9: "Music Artists/Features", #mentions all artists names
    10: "Confidence", #some explicit content/artists referencing themselves
    11: "Romance" #verse, baby, love
}
exploded['theme'] = exploded['cluster'].map(theme_map)

#compute theme percentages per artist - song level
exploded['song_id'] = exploded.groupby(['artist_clean', 'lyrics']).ngroup()
song_themes = exploded.groupby('song_id').agg({
    'artist_clean': 'first',
    'theme': lambda x: x.value_counts().idxmax()  # most common theme in the song
}).reset_index()
#count songs per artist per theme
song_theme_counts = song_themes.groupby(['artist_clean', 'theme']).size().reset_index(name='count')
# total songs per artist
total_songs = song_themes.groupby('artist_clean').size().reset_index(name='total')
#compute percentage of songs per theme
song_theme_percent = song_theme_counts.merge(total_songs, on='artist_clean')
song_theme_percent['percentage'] = song_theme_percent['count'] / song_theme_percent['total']
#display
song_theme_percent

#plot percentages per artist shown in a stacked bar chart (where each song is marked as a certain theme)
theme_wide_songs = song_theme_percent.pivot(index='artist_clean', columns='theme', values='percentage').fillna(0)
theme_wide_songs.plot(kind='bar', stacked=True, figsize=(12,6), colormap='tab20')
plt.ylabel('Percentage of Songs')
plt.xlabel('Artist')
plt.title('Theme Distribution per Artist (Songs)')
plt.gca().yaxis.set_major_formatter(plt.FuncFormatter(lambda y, _: '{:.0%}'.format(y)))
plt.legend(title='Theme', bbox_to_anchor=(1.05, 1), loc='upper left')
plt.tight_layout()
plt.show()

#plot song percentages per artist shown in individual pie charts
themes = song_theme_percent['theme'].unique()
colors = plt.get_cmap('tab20').colors[:len(themes)]
color_map = dict(zip(themes, colors))
for artist in song_theme_percent['artist_clean'].unique():
    data = song_theme_percent[song_theme_percent['artist_clean'] == artist]
    data = data.set_index('theme').reindex(themes, fill_value=0).reset_index()
    #legend includes themes and percentages
    legend_labels = [f"{t}: {p:.1%}" for t, p in zip(data['theme'], data['percentage'])]
    plt.figure(figsize=(6,6))
    plt.pie(data['percentage'], colors=[color_map[t] for t in data['theme']], startangle=140)
    plt.title(f'Theme Distribution for {artist.title()} (Song-Level)', fontsize=14)
    plt.legend(legend_labels, title="Themes", bbox_to_anchor=(1, 0.5), loc="center left")
    plt.tight_layout()
    plt.show()

#different approach - artist's percentage of theme = num of sentences in that theme/total num of sentences for that artist
theme_counts = exploded.groupby(['artist_clean', 'theme']).size().reset_index(name='count')
theme_counts['percentage'] = theme_counts.groupby('artist_clean')['count'].transform(lambda x: x / x.sum())
theme_percent = theme_counts
theme_percent

#individual pie charts for percentages by artist (using sentences instead of songs)
themes = sorted(theme_percent['theme'].dropna().unique())
colors = plt.get_cmap('tab20').colors[:len(themes)]
color_map = dict(zip(themes, colors))
for artist in sorted(theme_percent['artist_clean'].dropna().unique()):
    data = theme_percent[theme_percent['artist_clean'] == artist].copy()
    data = data.set_index('theme').reindex(themes, fill_value=0).reset_index()
    legend_labels = [f"{t}: {p:.1%}" for t, p in zip(data['theme'], data['percentage'])]
    plt.figure(figsize=(6, 6))
    plt.pie(data['percentage'], colors=[color_map[t] for t in data['theme']], startangle=140)
    plt.title(f"Theme Distribution for {artist.title()} (Sentence-level)", fontsize=14)
    plt.legend(legend_labels, title="Themes", bbox_to_anchor=(1, 0.5), loc="center left")
    plt.tight_layout()
    plt.show()

#bar graphs for most common themes among artists (each artist's top three themes)
colors = ["#2171b5", "#6baed6", "#c6dbef"]
theme_percent = theme_percent.copy()
theme_percent['rank'] = theme_percent.groupby('artist_clean')['percentage'].rank(method='first', ascending=False)
#get top three themes
top3 = theme_percent[theme_percent['rank'] <= 3]
artists = top3['artist_clean'].unique()
for artist in artists:
    data = top3[top3['artist_clean'] == artist].sort_values('percentage', ascending=False)
    plt.figure(figsize=(7,5))
    plt.bar(data['theme'], data['percentage'], color=colors)
    plt.ylabel("Percentage of Music")
    plt.title(f"Top 3 Themes for {artist.title()}")
    plt.gca().yaxis.set_major_formatter(FuncFormatter(lambda y, _: f"{y:.0%}"))
    plt.tight_layout()
    plt.show()